---
layout: post
title: Week 8
---

This week I was able to generate and retrieve the matrixes in the generated code sample from FaDE, and am working on integrating it into the rest of FaDE and testing it.

In the weekly meeting, we discussed if results need to be materialized or can be returned as a cursor. It was argued that we need to materialize all interventions for JOIN queries, as they need to access rows all over the intervention matrix expects intervention matrix order same as input order. For this reason, a "pipelined" approach, where parts of the intervention matrix could be generated and evaluated as needed, seemed to be infeasible.

Instead, it was discussed to generate a giant matrix as stream of vertical partitions, where given some chunk of memory, and knowing how many cols and rows the matrix has, it could be generated in multiple vertical partitions. Each would be sent to FaDE.

I'm working on creating a version of FaDE that uses materialized vs. cursor results, and plan to test both when both are finalized.

Example test implemenation of a materialized result (notice how the cursor has to be called repeatedly to get all results). 

```
while(chunk != nullptr) {
        idx_t cols = result.ColumnCount();
        idx_t rows = chunk->size();
        offset += rows;  

        int counter = 0;
        for (int col = 0; col < cols; col++) {
                    Vector v = chunk->data[col];
                    auto input_data = (unsigned long long *)FlatVector::GetData(v);

                    for (int row = 0; row < rows; ++row) {
                        for (int k = 0; k < 64; ++k) {
                            auto calc = (*values_arr_1_0)[offset + row] * (1 & (*input_data >> k));
                            auto new_row = (*keys_1)[offset + row];
                            auto new_col = col * 64 + k;
                            //std::cout << new_row << " " << new_col << std::endl;
                            (*var_1_0)[new_row][new_col] += calc;
                        }
                        input_data++;
                    }   
            }
        chunk = result.Fetch();
    }
```
